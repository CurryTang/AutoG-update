
        Imagine you are an expert graph data scientist, and now you are expected to construct graph schema based on the original
        inputs. You will be given an original schema represented in the dictionary format:
        <data>
            1. dataset_name: name of the dataset 
            2. tables: meta data for list of tables, each one will present following attributes
                1. name: table name
                2. source: source of the data, can either be a numpy .npz file or a parquet file
                3. columns: list of columns, each column will have following attributes
                    1. name: column name
                    2. dtype: column type, can be either text, categorical, float, primary_key, foreign_key, or multi_category.
                    primary_key and foreign_key are two special types of categorical columns, which presents a structural
                    relationship with other tables. Multi_category means this column is of list type, and each cell main contains
                    a list of categorical values. After a column is set as primary_key or foreign_key, it should not be changed to other types.
                    3. link_to (optional): if this column is a foreign key, point to which primary key from which table
            3. statistics of the table: statistics of the column value of tables. These statistics can be used to help you
            determine the characteristics of the columns. For example, if one categorical column only contains one unique value,
            then creating a node type based on this column can result in a super node, which is not ideal for graph construction.
            You should also determine whether two columns represent the same thing based on these statistics. 
            4. Dummy table is a special type of table. It's not explicitly defined with a table slot. It's defined in other tables, such as
            {"name": "nation", "dtype": "foreign_key", "link_to": "Country.CountryID"}. In this case, "Country" is a dummy table, which is not 
            explicitly defined in the tables slot.
        </data>                
        Here are the documents of the actions:
        
        Here is the introduction of the function generate_or_connect_dummy_table:
Description:
This function can be used in two ways:
1. Generate a dummy table with only one primary key
2. Turn an existing column with categorical type to an existing dummy table
"orig_col_name" must be a column with category type
Parameters:
dbb: the database object
base_table_name: the name of the original table
orig_col_name: the name of the original column in the original table, this should be a column with category type
new_table_name: the name of the new table to be created/connected
new_col_name: the name of the new column to be created/connected

Here is the introduction of the function connect_two_columns:
Description:
Connect two columns, this function can be used for the following case. Always put the column with category type in table 1.
1. A category column in table 1 is connected to a category column in table 2, in this case, a new dummy table will be created
2. A category column in table 1 is connected to a primary key column in table 2, in this case, the column in table 1 will be turned into a foreign key column. In case 2, table_2_col_name must be a primary key column
3. A category column in table 1 is connected to a non-category and non-primary key column in table 2, in this case, we will use a trick called Surrogate Key. 
4. If the column in table 1 is already a foreign key, then in this case it's probably a multi-column-point-to-one case, we need to update other fk columns too.
Parameters:
dbb: the database object
table_1_name: the name of the first table, 
table_1_col_name: the name of the column in the first table, this should be a column with category type
table_2_name: the name of the second table
table_2_col_name: the name of the column in the second table, this should be a column with category type

Here is the introduction of the function explode_multi_category_column:
Description:
Explode a multi-category column into multiple columns. You should determine whether to use this function. If you don't explode a multi-category column, it will be treated as a single category column automatically.
Parameters:
dbb: the database object
original_table: name of the original table where the multi-category column is located
multi_cat_col: the name of the multi-category column
primary_key_column: the name of the primary key column in the original table
new_table_name: the name of the new table to be created
new_col_name: the name of the new column to be created
dtype: the data type of the new column, if set to "foreign_key", this table will contain only "foreign_keys". In this case, it means you only want to use this column's relaion. If set to other types, this table will contain the original column's values, and a primary key will be added, this means you want to use this column's values.

Here is the introduction of the function generate_non_dummy_table:
Description:
Generate a non-dummy table with columns in the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
cols: the list of columns to be included in the new table and removed from the original table
new_table_name: the name of the new table to be created

Here is the introduction of the function remove_primary_key:
Description:
Remove a primary key constraint from a column in the original table
If the column is just an index, then the column will be removed from the table.
For example, if the schema is like {
    {"name": "id", "dtype": "primary_key"},
    {"name": "user", "dtype": "foreign_key", "link_to": "user.userID"},
    {"name": "book", "dtype": "foreign_key", "link_to": "book.bookID"},
}
In such case, it's clear that this table represents the role of an edge, while the presence of primary key prevents heuristic to turn this table into an edge. Primary key is not needed in this case.
In such case, we will remove the primary key constraint from the column.
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the column in the original table

Here is the introduction of the function add_primary_key:
Description:
Add a primary key column to the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the newly added primary key column

        
        Now, you need to 
        1. Actively think about whether any one of the four actions should be conducted; If not, you can select "None" and then halt the program.
        2. output all actions you can think of from the above list to perform, and output your selection in the following format. It should be noted that for those actions with sequential relation like one new categorical column generated after expanding a multi-category column, you don't need to generate in one round.
        
        <selection>
        [{'explanation': <explanation for the selection>, 'action': <first action>, 'parameters': <parameters for the first action> },
        {'explanation': <explanation for the selection>, 'action': <second action>, 'parameters': <parameters for the second action> }, ...
        ]
        </selection>

        
        3. If not more action, output <selection>None</selection>
        
        Example:
        
Table: Paper
{
  "Column": "PaperID",
  "data type": "primary_key"
}
{
    "Column": "Title",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Transformers",
    "5 sampled values": [
        "Transformers",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning",
        "Computer Vision"
    ]
}
{
    "Column": "Authors",
    "data type": "multi_category",
    "Number of unique values": 987,
    "Number of nan values": 0,
    "Number of total values": 74320,
    "Mode values": "Yann LeCun",
    "5 sampled values": [
        "Yann LeCun",
        "Geoffrey Hinton",
        "Yoshua Bengio",
        "Fei-Fei Li",
        "Jitendra Malik"
    ]
}
{
    "Column": "Journal",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "Year",
    "data type": "float",
}
{
    "Column": "Keywords",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Machine Learning",
    "5 sampled values": [
        "Machine Learning",
        "Deep Learning",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning"
    ]
}
{
    "Column": "Abstract",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "This paper presents a new model for graph neural networks.",
    "5 sampled values": [
        "This paper presents a new model for graph neural networks.",
        "This paper introduces a new reinforcement learning algorithm.",
        "This paper presents a new model for transformers.",
        "This paper presents a new model for meta learning.",
        "This paper presents a new model for computer vision."
    ]
}
{
    "Column": "Category",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": 3,
    "5 sampled values": [
        3,
        4,
        1,
        6,
        9
    ]
}
{
  "Column": "ItemID",
  "data type": "foreign_key"
}
Table: Journal
{
  "Column": "JournalID",
  "data type": "primary_key"
}
{
  "Column": "Name",
  "data type": "text", 
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "ImpactFactor",
    "data type": "float"
}
{
    "Column": "Country",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}
{
    "Column": "Publisher",
    "data type": "text",
    "Number of unique values": 9,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Springer",
    "5 sampled values": [
        "Springer",
        "Elsevier",
        "ACM",
        "IEEE",
        "Nature"
    ]
}
{
    "Column": "PublisherLocation",
    "data type": "category",
    "Number of unique values": 5,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}

</dataset_stats>
<tasks>
Now I want to train a model which can predict the category of a paper based on the information in the paper.
</tasks>
<schema>
{
        "dataset_name": "Papers",
        "tables": [
            {
                "name": "Paper",
                "source": "data/paper.npz",
                "columns": [
                    {"name": "PaperID", "dtype": "primary_key"},
                    {"name": "Title", "dtype": "text"},
                    {"name": "Authors", "dtype": "multi_category"},
                    {"name": "Journal", "dtype": "category"},
                    {"name": "Year", "dtype": "float"},
                    {"name": "Keywords", "dtype": "category"},
                    {"name": "Abstract", "dtype": "text"},
                    {"name": "Category", "dtype": "category"}
                ]
            }, 
            {
                "name": "Journal",
                "source": "data/journal.npz",
                "columns": [
                    {"name": "JournalID", "dtype": "primary_key"},
                    {"name": "Name", "dtype": "text"},
                    {"name": "ImpactFactor", "dtype": "float"},
                    {"name": "Country", "dtype": "category"},
                    {"name": "Publisher", "dtype": "text"},
                    {"name": "PublisherLocation", "dtype": "category"}
                ]
            }
        ]
    }
</schema>
Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
<similarity>
The pair with the 1st highest similarity is column "Journal" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.885
The pair with the 2nd highest similarity is column "Authors" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.743
The pair with the 3rd highest similarity is column "Authors" from Table "Paper" and column "Country" from Table "Journal" with similarity 0.723
</similarity>
</input>



We need to think about whether we need to do one of the six actions:
1. First, for explode_multi_category_column, the Authors of the paper are in a multi-category column. Moreover, author is closely related to the category of the paper, so the relationship Paper-Author-Paper can be very useful. So, we need to explode this multi category column.
2. For connect_two_columns, the Journal column in the Paper table and the  column Name in the Journal table are highly similar, so we can connect these two columns with a foreign key constraint. Other pairs like Authors and Name, Authors and Country are not similar enough to be connected.
3. For generate_non_dummy_table, the Publisher and PublisherLocation columns are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns.
4. For generate_or_connect_dummy_table, we need to find those categorical columns beneficial for downstream task. We have categorical columns (Journal has been deleted in step 2, Category is the final objective) Keyword, Country, this will result in relationship Paper-Keyword-Paper and Paper-Journal-Country-Journal-Paper respectively. Since the target is to predict the category of a paper, we can generate a dummy table for the column Keyword since paper sharing the same keyword are highly likely to share the same category. Country may be not beneficial since it doesn't present a strong semantic relationship with the category. 
5. For remove_primary_key and add_primary_key, there's no unreasonable primary key or missing primary key in the table, so we don't need to do this action. as a result, we have the following actions
<selection>
        [{{'explanation': "Author is multi-category and Paper-Author-Paper is probably useful. We set the dtype to foreign_key because we want to use the relation", 'action': 'explode_multi_category_column', 'parameters': {'original_table': 'Paper', 'multi_cat_col': 'Author', primary_key_column: 'PaperID', 'new_table_name': 'Author', 'new_col_name': 'AuthorName', 'dtype': 'foreign_key'}},
        {{'explanation': 'the Journal column in the Paper table and the  column Name in the Journal table are highly similar, both of them should refer to the name of the journal', 'action': 'connect_two_columns', 'parameters': {'table_1_name': 'Paper', 'table_1_col_name': 'Journal', 'table_2_name': 'Journal', 'table_2_col_name': 'Name', 'new_table_name': "", 'new_table_col_name': "" }}, 
        {{'explanation': 'Publisher and PublisherLocation are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns', 'action': 'generate_non_dummy_table', 'parameters': {'base_table_name': 'Paper', 'cols': ['Publisher', 'PublisherLocation'],  'new_table_name': 'Publisher'}},
        {{'explanation': 'Keyword is a categorical column which can be used to generate a dummy table. Country is not beneficial for the downstream task', 'action': 'generate_or_connect_dummy_table', 'parameters': {'base_table_name': 'Paper', 'orig_col_name': 'Keyword', 'new_table_name': 'Keyword', 'new_col_name': 'Keyword'}},
        ]
        </selection>

    

        
        History Actions:
        First iteration, no history yet


        
        <input>
        <dataset_stats>
        Analysis for Table QueryResult:
  Column: queryId
    Max: 980503
    Min: 1
    Mode: 53466
    Sampled Values: [375753 664729 441973 858322 153707]
    Number of Total Values: 92271275
    Number of Unique Values: 636160
  Column: itemId
    Max: 736383
    Min: 1
    Mode: 4991
    Sampled Values: [ 20635  30293 109583   2323  56627]
    Number of Total Values: 92271275
    Number of Unique Values: 129512
  Column: timestamp
    Max: 2016-10-26T18:50:30.578000000
    Min: 2016-01-01T01:08:12.072000000
    Mode: 2016-02-11 21:48:20.387000
    Sampled Values: ['2016-05-05T14:11:17.335000000' '2016-04-26T08:49:15.367000000'
 '2016-04-17T05:26:09.648000000' '2016-05-13T20:14:42.156000000'
 '2016-03-22T06:23:56.596000000']
    Number of Total Values: 92271275
    Number of Unique Values: 636137

Analysis for Table Click:
  Column: queryId
    Max: 980503
    Min: 1
    Mode: 856206
    Sampled Values: [ 73661 648147 535368 385338 608169]
    Number of Total Values: 1127760
    Number of Unique Values: 633730
  Column: itemId
    Max: 731041
    Min: 2
    Mode: 79141
    Sampled Values: [  6898  90787 196999  50885  52870]
    Number of Total Values: 1127760
    Number of Unique Values: 74635
  Column: timestamp
    Max: 2016-10-26T18:52:14.376000000
    Min: 2016-01-01T01:08:15.784000000
    Mode: 2016-03-18 02:05:10.580000
    Sampled Values: ['2016-05-07T10:10:36.626000000' '2016-04-26T01:02:26.824000000'
 '2016-03-20T16:49:16.586000000' '2016-04-14T16:26:55.808000000'
 '2016-03-14T23:51:02.519000000']
    Number of Total Values: 1127760
    Number of Unique Values: 1117374

Analysis for Table View:
  Column: view_session
    Max: 600687
    Min: 1
    Mode: 480263
    Sampled Values: [124944 311734 410623 192065 434691]
    Number of Total Values: 1235380
    Number of Unique Values: 310324
  Column: view_user
    Max: nan
    Min: nan
    Mode: 17732.0
    Sampled Values: [85579.    nan    nan    nan    nan]
    Number of Total Values: 1235380
    Number of Unique Values: 87934
  Column: itemId
    Max: 733848
    Min: 1
    Mode: 79141
    Sampled Values: [126353  39090 375427  68434  36334]
    Number of Total Values: 1235380
    Number of Unique Values: 122993
  Column: timestamp
    Max: 2016-06-02T00:19:05.937000000
    Min: 2016-01-01T01:08:17.154000000
    Mode: 2016-02-03 07:44:21.611000
    Sampled Values: ['2016-02-04T13:32:11.239000000' '2016-05-21T09:12:33.289000000'
 '2016-05-18T12:14:49.011000000' '2016-05-22T19:53:22.892000000'
 '2016-03-14T07:43:48.664000000']
    Number of Total Values: 1235380
    Number of Unique Values: 1235286

Analysis for Table Purchase:
  Column: purchase_session
    Max: 600661
    Min: 150
    Mode: 13366
    Sampled Values: [253835 155377  23728  15159  41683]
    Number of Total Values: 18025
    Number of Unique Values: 12630
  Column: purchaser
    Max: nan
    Min: nan
    Mode: 10591.0
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 18025
    Number of Unique Values: 4425
  Column: ordernumber
    Max: 22817
    Min: 2
    Mode: 5580
    Sampled Values: [14195 16297  1405 11068  3942]
    Number of Total Values: 18025
    Number of Unique Values: 13506
  Column: itemId
    Max: 691863
    Min: 2
    Mode: 10858
    Sampled Values: [126912  31986  69167   6713  82312]
    Number of Total Values: 18025
    Number of Unique Values: 11244
  Column: timestamp
    Max: 2016-11-09T16:30:29.641000000
    Min: 2016-01-02T08:51:07.714000000
    Mode: 2016-03-17 06:09:06.839000
    Sampled Values: ['2016-05-27T06:51:11.308000000' '2016-05-18T16:53:52.011000000'
 '2016-06-10T23:37:53.005000000' '2016-04-26T19:15:09.390000000'
 '2016-05-21T22:26:43.743000000']
    Number of Total Values: 18025
    Number of Unique Values: 13657

Analysis for Table QuerySearchstringToken:
  Column: queryId
    Max: 53453
    Min: 1
    Mode: 20595
    Sampled Values: [41156 25426 10717 21969 21871]
    Number of Total Values: 138260
    Number of Unique Values: 51888
  Column: search_token
    Mode: 16655
    Sampled Values: ['77442...', '146372...', '528783...', '529291...', '529116...']
    Number of Total Values: 138260
    Number of Unique Values: 19075

Analysis for Table Query:
  Column: queryId
    Max: 980503
    Min: 1
    Mode: 1
    Sampled Values: [135430  69346 694379 427045 293304]
    Number of Total Values: 636160
    Number of Unique Values: 636160
  Column: query_sessionId
    Max: 600687
    Min: 1
    Mode: 48445
    Sampled Values: [166010 118754  55957 137310 214829]
    Number of Total Values: 636160
    Number of Unique Values: 368782
  Column: query_userId
    Max: nan
    Min: nan
    Mode: 24034.0
    Sampled Values: [ 33789.     nan     nan 101159.  49326.]
    Number of Total Values: 636160
    Number of Unique Values: 140387
  Column: duration
    Max: 73021
    Min: 39
    Mode: 1013
    Sampled Values: [ 929 2959 2290  220 4367]
    Number of Total Values: 636160
    Number of Unique Values: 7046
  Column: categoryId
    Max: 1297
    Min: 0
    Mode: 0
    Sampled Values: [ 822  755 1174 1127  571]
    Number of Total Values: 636160
    Number of Unique Values: 1101
  Column: timestamp
    Max: 2016-10-26T18:50:30.578000000
    Min: 2016-01-01T01:08:12.072000000
    Mode: 2016-02-05 20:34:01.122000
    Sampled Values: ['2016-04-09T07:09:13.379000000' '2016-04-15T09:45:44.851000000'
 '2016-05-27T02:49:00.294000000' '2016-03-27T10:44:02.772000000'
 '2016-02-24T06:16:01.431000000']
    Number of Total Values: 636160
    Number of Unique Values: 636137

Analysis for Table Product:
  Column: itemId
    Max: 736383
    Min: 1
    Mode: 1
    Sampled Values: [190498 344880 493549 505273 188757]
    Number of Total Values: 184047
    Number of Unique Values: 184047
  Column: categoryId
    Max: 1297
    Min: 2
    Mode: 807
    Sampled Values: [422 591 291 949 581]
    Number of Total Values: 184047
    Number of Unique Values: 1217
  Column: pricelog2
    Max: 15
    Min: 0
    Mode: 0
    Sampled Values: [8 0 6 6 0]
    Number of Total Values: 184047
    Number of Unique Values: 13
  Column: name_tokens
  This is a very large column
  Sampled values: [14140, 91983, 91983] [514132, 514132, 96631, 510711] [62897, 62896, 22144, 22144, 14755, 62903] 


        </dataset_stats>
        <task>
        This task is to predict whether a user will purchase an item given the item information and user-item structural information. In the task table, you are given itemId, queryId, timestamp, and clicked. The target is clicked. Moreover, itemId is a foreign key pointing to itemId of the Product table. purchase_session is a foreign key pointing to the Session table, which inspires that there should be one table Session
        </task>
        <schema>
        {"dataset_name":"diginetica","tables":[{"name":"QueryResult","source":"data/query_results.pqt","format":"parquet","columns":[{"name":"queryId","dtype":"category","description":"This column likely represents unique query identifiers, as it has a large number of unique values."},{"name":"itemId","dtype":"category","description":"This column likely represents unique item identifiers, as it has a large number of unique values."},{"name":"timestamp","dtype":"datetime","description":"This column represents the timestamp of query-related events, containing full datetime values."}],"time_column":null},{"name":"Click","source":"data/clicks.pqt","format":"parquet","columns":[{"name":"queryId","dtype":"category","description":"This column likely represents unique query identifiers, as it has a large number of unique values."},{"name":"itemId","dtype":"category","description":"This column likely represents unique item identifiers, as it has a large number of unique values."},{"name":"timestamp","dtype":"datetime","description":"This column represents the timestamp of click-related events, containing full datetime values."}],"time_column":null},{"name":"View","source":"data/item_views.pqt","format":"parquet","columns":[{"name":"view_session","dtype":"category","description":"This column likely represents unique session identifiers for views, as it has a significant number of unique values."},{"name":"view_user","dtype":"category","description":"This column likely represents unique user identifiers for views, as it has many unique values but also contains missing values."},{"name":"itemId","dtype":"category","description":"This column likely represents unique item identifiers, as it has a large number of unique values."},{"name":"timestamp","dtype":"datetime","description":"This column represents the timestamp of view-related events, containing full datetime values."}],"time_column":null},{"name":"Purchase","source":"data/purchases.pqt","format":"parquet","columns":[{"name":"purchase_session","dtype":"category","description":"This column likely represents unique session identifiers for purchases, as it has a significant number of unique values."},{"name":"purchaser","dtype":"category","description":"This column likely represents unique purchaser identifiers, as it has many unique values but also contains missing values."},{"name":"ordernumber","dtype":"category","description":"This column likely represents unique order numbers, as it has many unique values."},{"name":"itemId","dtype":"category","description":"This column likely represents unique item identifiers, as it has a large number of unique values."},{"name":"timestamp","dtype":"datetime","description":"This column represents the timestamp of purchase-related events, containing full datetime values."}],"time_column":null},{"name":"QuerySearchstringToken","source":"data/query_searchstring_tokens.pqt","format":"parquet","columns":[{"name":"queryId","dtype":"category","description":"This column likely represents unique query identifiers, as it has a significant number of unique values."},{"name":"search_token","dtype":"category","description":"This column represents a list of search tokens associated with a query, making it a multi-category field."}],"time_column":null},{"name":"Query","source":"data/queries.pqt","format":"parquet","columns":[{"name":"queryId","dtype":"primary_key","description":"This column likely represents unique query identifiers, as each value appears to be unique."},{"name":"query_sessionId","dtype":"category","description":"This column likely represents session identifiers for queries, as it has a moderate number of unique values."},{"name":"query_userId","dtype":"category","description":"This column likely represents user identifiers associated with queries, but contains missing values."},{"name":"duration","dtype":"float","description":"This column likely represents the duration of a query event, as it contains numerical values with many unique values."},{"name":"categoryId","dtype":"category","description":"This column likely represents a categorical classification for queries, as the number of unique values is limited."},{"name":"timestamp","dtype":"datetime","description":"This column represents the timestamp of query-related events, containing full datetime values."}],"time_column":null},{"name":"Product","source":"data/products.pqt","format":"parquet","columns":[{"name":"itemId","dtype":"primary_key","description":"This column likely represents unique product identifiers, as each value appears to be unique."},{"name":"categoryId","dtype":"category","description":"This column represents product categories, as the number of unique values is limited."},{"name":"pricelog2","dtype":"float","description":"This column represents a numerical price transformation (likely log-scaled), as it contains numerical values with some distinct values."},{"name":"name_tokens","dtype":"multi_category","description":"This column contains a list of tokens associated with product names, making it a multi-category field."}],"time_column":null}],"tasks":[{"name":"purchase","source":"purchase/purchase_{split}.pqt","format":"parquet","columns":[{"name":"itemId","dtype":"foreign_key"},{"name":"purchase_session","dtype":"category"},{"name":"timestamp","dtype":"datetime"}],"time_column":null,"evaluation_metric":"mrr","target_column":"itemId","target_table":"Purchase","task_type":"retrieval","key_prediction_label_column":"label","key_prediction_query_idx_column":"query_idx"}],"method":"r2n","column_groups":null}
        </schema>
        Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
        <similarity>
        The pair with the 1st highest similarity is column "itemId" from Table "Click" and column "itemId" from Table "View" with similarity 0.988
The pair with the 2nd highest similarity is column "itemId" from Table "View" and column "itemId" from Table "Purchase" with similarity 0.972
The pair with the 3rd highest similarity is column "itemId" from Table "Click" and column "itemId" from Table "Purchase" with similarity 0.967
The pair with the 4th highest similarity is column "itemId" from Table "QueryResult" and column "itemId" from Table "Click" with similarity 0.964
The pair with the 5th highest similarity is column "categoryId" from Table "Query" and column "categoryId" from Table "Product" with similarity 0.963
The pair with the 6th highest similarity is column "itemId" from Table "QueryResult" and column "itemId" from Table "View" with similarity 0.951
The pair with the 7th highest similarity is column "itemId" from Table "Click" and column "itemId" from Table "Product" with similarity 0.932
The pair with the 8th highest similarity is column "itemId" from Table "View" and column "itemId" from Table "Product" with similarity 0.931
The pair with the 9th highest similarity is column "queryId" from Table "QueryResult" and column "queryId" from Table "Click" with similarity 0.929
The pair with the 10th highest similarity is column "itemId" from Table "QueryResult" and column "itemId" from Table "Product" with similarity 0.927
The pair with the 11st highest similarity is column "view_user" from Table "View" and column "query_userId" from Table "Query" with similarity 0.926
The pair with the 12nd highest similarity is column "itemId" from Table "QueryResult" and column "itemId" from Table "Purchase" with similarity 0.917
The pair with the 13rd highest similarity is column "itemId" from Table "Purchase" and column "itemId" from Table "Product" with similarity 0.914
The pair with the 14th highest similarity is column "queryId" from Table "Click" and column "queryId" from Table "Query" with similarity 0.911
The pair with the 15th highest similarity is column "queryId" from Table "QueryResult" and column "queryId" from Table "QuerySearchstringToken" with similarity 0.885
The pair with the 16th highest similarity is column "queryId" from Table "Click" and column "queryId" from Table "QuerySearchstringToken" with similarity 0.880
The pair with the 17th highest similarity is column "queryId" from Table "QueryResult" and column "queryId" from Table "Query" with similarity 0.879
The pair with the 18th highest similarity is column "queryId" from Table "QuerySearchstringToken" and column "queryId" from Table "Query" with similarity 0.873
The pair with the 19th highest similarity is column "queryId" from Table "Query" and column "query_sessionId" from Table "Query" with similarity 0.800
The pair with the 20th highest similarity is column "queryId" from Table "QuerySearchstringToken" and column "query_sessionId" from Table "Query" with similarity 0.787

        </similarity>
        </input>
        Return your output in the json format inside <selection></selection>.
    