
        Imagine you are an expert graph data scientist, and now you are expected to construct graph schema based on the original
        inputs. You will be given an original schema represented in the dictionary format:
        <data>
            1. dataset_name: name of the dataset 
            2. tables: meta data for list of tables, each one will present following attributes
                1. name: table name
                2. source: source of the data, can either be a numpy .npz file or a parquet file
                3. columns: list of columns, each column will have following attributes
                    1. name: column name
                    2. dtype: column type, can be either text, categorical, float, primary_key, foreign_key, or multi_category.
                    primary_key and foreign_key are two special types of categorical columns, which presents a structural
                    relationship with other tables. Multi_category means this column is of list type, and each cell main contains
                    a list of categorical values. dtype 'split' is used to generate the training/validation/test split. Don't change
                    this column. After a column is set as primary_key or foreign_key, it should not be changed to other types.
                    3. link_to (optional): if this column is a foreign key, point to which primary key from which table
            3. statistics of the table: statistics of the column value of tables. These statistics can be used to help you
            determine the characteristics of the columns. For example, if one categorical column only contains one unique value,
            then creating a node type based on this column can result in a super node, which is not ideal for graph construction.
            You should also determine whether two columns represent the same thing based on these statistics. 
            4. Dummy table is a special type of table. It's not explicitly defined with a table slot. It's defined in other tables, such as
            {"name": "Country", "dtype": "foreign_key", "link_to": "Country.CountryID"}. In this case, "Country" is a dummy table, which is not 
            explicitly defined in the tables slot.
        </data>                
        Here are the documents of the actions:
        
        Here is the introduction of the function generate_or_connect_dummy_table:
Description:
This function can be used in two ways:
1. Generate a dummy table with only one primary key
2. Turn an existing column with categorical type to an existing dummy table
"orig_col_name" must be a column with category type
Parameters:
dbb: the database object
base_table_name: the name of the original table
orig_col_name: the name of the original column in the original table, this should be a column with category type
new_table_name: the name of the new table to be created/connected
new_col_name: the name of the new column to be created/connected

Here is the introduction of the function connect_two_columns:
Description:
Connect two columns, this function can be used for the following case. Always put the column with category type in table 1.
1. A category column in table 1 is connected to a category column in table 2, in this case, a new dummy table will be created
2. A category column in table 1 is connected to a primary key column in table 2, in this case, the column in table 1 will be turned into a foreign key column. In case 2, table_2_col_name must be a primary key column
3. A category column in table 1 is connected to a non-category and non-primary key column in table 2, in this case, we will use a trick called Surrogate Key. 
Parameters:
dbb: the database object
table_1_name: the name of the first table, 
table_1_col_name: the name of the column in the first table, this should be a column with category type
table_2_name: the name of the second table
table_2_col_name: the name of the column in the second table, this should be a column with category type
new_table_name: the name of the new table to be created, can leave it empty for case 2 and 3
new_table_col_name: the name of the new column to be created, can leave it empty for case 2 and 3

Here is the introduction of the function explode_multi_category_column:
Description:
Explode a multi-category column into multiple columns
Parameters:
dbb: the database object
original_table: name of the original table where the multi-category column is located
multi_cat_col: the name of the multi-category column
primary_key_column: the name of the primary key column in the original table
new_table_name: the name of the new table to be created
new_col_name: the name of the new column to be created
dtype: the data type of the new column, if set to "foreign_key", this table will contain only "foreign_keys". In this case, it means you only want to use this column's relaion. If set to other types, this table will contain the original column's values, and a primary key will be added, this means you want to use this column's values.

Here is the introduction of the function generate_non_dummy_table:
Description:
Generate a non-dummy table with columns in the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
cols: the list of columns to be included in the new table and removed from the original table
new_table_name: the name of the new table to be created

Here is the introduction of the function remove_primary_key:
Description:
Remove a primary key constraint from a column in the original table
If the column is just an index, then the column will be removed from the table.
For example, if the schema is like {
    {"name": "id", "dtype": "primary_key"},
    {"name": "user", "dtype": "foreign_key", "link_to": "user.userID"},
    {"name": "book", "dtype": "foreign_key", "link_to": "book.bookID"},
}
In such case, it's clear that this table represents the role of an edge, while the presence of primary key prevents heuristic to turn this table into an edge. Primary key is not needed in this case.
In such case, we will remove the primary key constraint from the column.
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the column in the original table

Here is the introduction of the function add_primary_key:
Description:
Add a primary key column to the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the newly added primary key column
        
        You also need to consider how to construct the graph, with two options to choose from:
        * r2n: Row2Node, each table will be converted to a node in the constructed heterogeneous graph. You should adopt
        this method if you think that every table should be converted to a node.
        * r2ne: Row2Node with Edge, each table will be converted to a node or an edge in the constructed heterogeneous graph. 
        Specifically, for a table with two foreign key columns and no primary key column, it will be converted to an edge.
        You should adopt this method if you think that some tables should be converted to edges.
        
        Now, you need to 
        1. Actively think about whether any one of the four actions should be conducted; If not, you can select "None" and then halt the program.
        2. output all actions you can think of from the above list to perform, and output your selection in the following format. It should be noted that for those actions with sequential relation like one new categorical column generated after expanding a multi-category column, you don't need to generate in one round.
        
        <selection>
        [{'explanation': <explanation for the selection>, 'action': <first action>, 'parameters': <parameters for the first action> },
        {'explanation': <explanation for the selection>, 'action': <second action>, 'parameters': <parameters for the second action> }, ...
        ]
        </selection>

        
        3. After generating the configuration file of the graph, choose one heuristic method to construct the graph schema. This selection should be based on current schema you generate but not the final one.
        <construction>
            {Your selection here}
        </construction>
        
        Example:
        
Table: Paper
{
  "Column": "PaperID",
  "data type": "primary_key"
}
{
    "Column": "Title",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Transformers",
    "5 sampled values": [
        "Transformers",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning",
        "Computer Vision"
    ]
}
{
    "Column": "Authors",
    "data type": "multi_category",
    "Number of unique values": 987,
    "Number of nan values": 0,
    "Number of total values": 74320,
    "Mode values": "Yann LeCun",
    "5 sampled values": [
        "Yann LeCun",
        "Geoffrey Hinton",
        "Yoshua Bengio",
        "Fei-Fei Li",
        "Jitendra Malik"
    ]
}
{
    "Column": "Journal",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "Year",
    "data type": "float",
}
{
    "Column": "Keywords",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Machine Learning",
    "5 sampled values": [
        "Machine Learning",
        "Deep Learning",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning"
    ]
}
{
    "Column": "Abstract",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "This paper presents a new model for graph neural networks.",
    "5 sampled values": [
        "This paper presents a new model for graph neural networks.",
        "This paper introduces a new reinforcement learning algorithm.",
        "This paper presents a new model for transformers.",
        "This paper presents a new model for meta learning.",
        "This paper presents a new model for computer vision."
    ]
}
{
    "Column": "Category",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": 3,
    "5 sampled values": [
        3,
        4,
        1,
        6,
        9
    ]
}
{
  "Column": "ItemID",
  "data type": "foreign_key"
}
Table: Journal
{
  "Column": "JournalID",
  "data type": "primary_key"
}
{
  "Column": "Name",
  "data type": "text", 
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "ImpactFactor",
    "data type": "float"
}
{
    "Column": "Country",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}
{
    "Column": "Publisher",
    "data type": "text",
    "Number of unique values": 9,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Springer",
    "5 sampled values": [
        "Springer",
        "Elsevier",
        "ACM",
        "IEEE",
        "Nature"
    ]
}
{
    "Column": "PublisherLocation",
    "data type": "category",
    "Number of unique values": 5,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}

</dataset_stats>
<tasks>
Now I want to train a model which can predict the category of a paper based on the information in the paper.
</tasks>
<schema>
{
        "dataset_name": "Papers",
        "tables": [
            {
                "name": "Paper",
                "source": "data/paper.npz",
                "columns": [
                    {"name": "PaperID", "dtype": "primary_key"},
                    {"name": "Title", "dtype": "text"},
                    {"name": "Authors", "dtype": "multi_category"},
                    {"name": "Journal", "dtype": "category"},
                    {"name": "Year", "dtype": "float"},
                    {"name": "Keywords", "dtype": "category"},
                    {"name": "Abstract", "dtype": "text"},
                    {"name": "Category", "dtype": "category"}
                ]
            }, 
            {
                "name": "Journal",
                "source": "data/journal.npz",
                "columns": [
                    {"name": "JournalID", "dtype": "primary_key"},
                    {"name": "Name", "dtype": "text"},
                    {"name": "ImpactFactor", "dtype": "float"},
                    {"name": "Country", "dtype": "category"},
                    {"name": "Publisher", "dtype": "text"},
                    {"name": "PublisherLocation", "dtype": "category"}
                ]
            }
        ]
    }
</schema>
Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
<similarity>
The pair with the 1st highest similarity is column "Journal" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.885
The pair with the 2nd highest similarity is column "Authors" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.743
The pair with the 3rd highest similarity is column "Authors" from Table "Paper" and column "Country" from Table "Journal" with similarity 0.723
</similarity>
</input>



We need to think about whether we need to do one of the six actions:
1. First, for explode_multi_category_column, the Authors of the paper are in a multi-category column. Moreover, author is closely related to the category of the paper, so the relationship Paper-Author-Paper can be very useful. So, we need to explode this multi category column.
2. For connect_two_columns, the Journal column in the Paper table and the  column Name in the Journal table are highly similar, so we can connect these two columns with a foreign key constraint. Other pairs like Authors and Name, Authors and Country are not similar enough to be connected.
3. For generate_non_dummy_table, the Publisher and PublisherLocation columns are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns.
4. For generate_or_connect_dummy_table, we need to find those categorical columns beneficial for downstream task. We have categorical columns (Journal has been deleted in step 2, Category is the final objective) Keyword, Country, this will result in relationship Paper-Keyword-Paper and Paper-Journal-Country-Journal-Paper respectively. Since the target is to predict the category of a paper, we can generate a dummy table for the column Keyword since paper sharing the same keyword are highly likely to share the same category. Country may be not beneficial since it doesn't present a strong semantic relationship with the category. 
5. For remove_primary_key and add_primary_key, there's no unreasonable primary key or missing primary key in the table, so we don't need to do this action. as a result, we have the following actions
<selection>
        [{{'explanation': "Author is multi-category and Paper-Author-Paper is probably useful. We set the dtype to foreign_key because we want to use the relation", 'action': 'explode_multi_category_column', 'parameters': {'original_table': 'Paper', 'multi_cat_col': 'Author', primary_key_column: 'PaperID', 'new_table_name': 'Author', 'new_col_name': 'AuthorName', 'dtype': 'foreign_key'}},
        {{'explanation': 'the Journal column in the Paper table and the  column Name in the Journal table are highly similar, both of them should refer to the name of the journal', 'action': 'connect_two_columns', 'parameters': {'table_1_name': 'Paper', 'table_1_col_name': 'Journal', 'table_2_name': 'Journal', 'table_2_col_name': 'Name', 'new_table_name': "", 'new_table_col_name': "" }}, 
        {{'explanation': 'Publisher and PublisherLocation are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns', 'action': 'generate_non_dummy_table', 'parameters': {'base_table_name': 'Paper', 'cols': ['Publisher', 'PublisherLocation'],  'new_table_name': 'Publisher'}},
        {{'explanation': 'Keyword is a categorical column which can be used to generate a dummy table. Country is not beneficial for the downstream task', 'action': 'generate_or_connect_dummy_table', 'parameters': {'base_table_name': 'Paper', 'orig_col_name': 'Keyword', 'new_table_name': 'Keyword', 'new_col_name': 'Keyword'}},
        ]
        </selection>

    

        
        History Actions:
        First iteration, no history yet


        
        <input>
        <dataset_stats>
        Analysis for Table Transaction:
  Column: ProductCode
    Mode: W
    Sampled Values: ['W' 'W' 'W' 'W' 'W']
    Number of Total Values: 590540
    Number of Unique Values: 5
  Column: card_meta_info_1
    Max: 18396
    Min: 1000
    Mode: 7919
    Sampled Values: [ 7826 12615 13413  2616  6481]
    Number of Total Values: 590540
    Number of Unique Values: 13553
  Column: card_meta_info_2
    Max: nan
    Min: nan
    Mode: 321.0
    Sampled Values: [170. 476. 483. 488. 321.]
    Number of Total Values: 590540
    Number of Unique Values: 500
  Column: card_meta_info_3
    Max: nan
    Min: nan
    Mode: 150.0
    Sampled Values: [150. 150. 150. 150. 150.]
    Number of Total Values: 590540
    Number of Unique Values: 114
  Column: card_meta_info_4
    Mode: visa
    Sampled Values: ['visa' 'mastercard' 'visa' 'visa' 'mastercard']
    Number of Total Values: 590540
    Number of Unique Values: 4
  Column: card_meta_info_5
    Max: nan
    Min: nan
    Mode: 226.0
    Sampled Values: [224. 138. 219. 226. 226.]
    Number of Total Values: 590540
    Number of Unique Values: 119
  Column: card_meta_info_6
    Mode: debit
    Sampled Values: ['debit' 'credit' 'credit' 'credit' 'debit']
    Number of Total Values: 590540
    Number of Unique Values: 4
  Column: purchaser billing region
    Max: nan
    Min: nan
    Mode: 299.0
    Sampled Values: [126. 485. 330. 242. 204.]
    Number of Total Values: 590540
    Number of Unique Values: 332
  Column: purchaser billing country
    Max: nan
    Min: nan
    Mode: 87.0
    Sampled Values: [87. 87. 87. 87. 87.]
    Number of Total Values: 590540
    Number of Unique Values: 74
  Column: purchaser email domain
    Mode: gmail.com
    Sampled Values: [nan 'yahoo.com' 'yahoo.com' 'yahoo.com' 'netzero.com']
    Number of Total Values: 590540
    Number of Unique Values: 59
  Column: recipient email domain
    Mode: gmail.com
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 590540
    Number of Unique Values: 60
  Column: match_1
    Mode: T
    Sampled Values: [nan 'T' 'T' 'T' 'T']
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_2
    Mode: T
    Sampled Values: ['T' nan nan nan 'T']
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_3
    Mode: T
    Sampled Values: ['T' 'F' nan nan nan]
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_4
    Mode: M0
    Sampled Values: ['M2' nan nan nan nan]
    Number of Total Values: 590540
    Number of Unique Values: 3
  Column: match_5
    Mode: F
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_6
    Mode: F
    Sampled Values: ['F' 'F' nan nan nan]
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_7
    Mode: F
    Sampled Values: ['T' 'F' 'F' 'F' nan]
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_8
    Mode: F
    Sampled Values: [nan 'T' 'F' nan 'T']
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: match_9
    Mode: T
    Sampled Values: ['T' 'T' nan nan 'F']
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: TransactionID
    Max: 3577539
    Min: 2987000
    Mode: 2987000
    Sampled Values: [3484350 3070079 3476118 3284957 3000366]
    Number of Total Values: 590540
    Number of Unique Values: 590540
  Column: isFraud
    Max: 1
    Min: 0
    Mode: 0
    Sampled Values: [0 0 0 0 0]
    Number of Total Values: 590540
    Number of Unique Values: 2
  Column: TransactionAmt
    Max: 10.37156404479566
    Min: 0.22394323148477407
    Mode: 4.0943445622221
    Sampled Values: [4.11087386 3.90955997 4.61512052 2.67992504 4.30406509]
    Number of Total Values: 590540
    Number of Unique Values: 20902
  Column: distance
Column is multi-dimensional. Probably an embedding type. Usually not of interest
  Column: payment_card_related_counting
Column is multi-dimensional. Probably an embedding type. Usually not of interest
  Column: timedelta
Column is multi-dimensional. Probably an embedding type. Usually not of interest
  Column: vesta_features
Column is multi-dimensional. Probably an embedding type. Usually not of interest

Analysis for Table Identity:
  Column: identity_12_info
    Mode: NotFound
    Sampled Values: ['Found' 'NotFound' 'NotFound' 'NotFound' 'NotFound']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_13_info
    Max: nan
    Min: nan
    Mode: 52.0
    Sampled Values: [52. 64. 64. 52. 52.]
    Number of Total Values: 144233
    Number of Unique Values: 54
  Column: identity_14_info
    Max: nan
    Min: nan
    Mode: -300.0
    Sampled Values: [-480. -480.   nan   nan   nan]
    Number of Total Values: 144233
    Number of Unique Values: 25
  Column: identity_15_info
    Mode: Found
    Sampled Values: ['Found' 'New' 'New' 'New' 'New']
    Number of Total Values: 144233
    Number of Unique Values: 3
  Column: identity_16_info
    Mode: Found
    Sampled Values: [nan 'NotFound' 'Found' 'Found' 'NotFound']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_17_info
    Max: nan
    Min: nan
    Mode: 166.0
    Sampled Values: [225. 225. 121. 166. 166.]
    Number of Total Values: 144233
    Number of Unique Values: 104
  Column: identity_18_info
    Max: nan
    Min: nan
    Mode: 15.0
    Sampled Values: [nan nan 15. nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 18
  Column: identity_19_info
    Max: nan
    Min: nan
    Mode: 266.0
    Sampled Values: [193. 266. 321. 266. 529.]
    Number of Total Values: 144233
    Number of Unique Values: 522
  Column: identity_20_info
    Max: nan
    Min: nan
    Mode: 507.0
    Sampled Values: [266. 214. 563. 222. 507.]
    Number of Total Values: 144233
    Number of Unique Values: 394
  Column: identity_21_info
    Max: nan
    Min: nan
    Mode: 252.0
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 490
  Column: identity_22_info
    Max: nan
    Min: nan
    Mode: 14.0
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 25
  Column: identity_23_info
    Mode: IP_PROXY:TRANSPARENT
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 3
  Column: identity_24_info
    Max: nan
    Min: nan
    Mode: 11.0
    Sampled Values: [nan 15. nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 12
  Column: identity_25_info
    Max: nan
    Min: nan
    Mode: 321.0
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 341
  Column: identity_26_info
    Max: nan
    Min: nan
    Mode: 161.0
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 95
  Column: identity_27_info
    Mode: Found
    Sampled Values: [nan nan nan nan nan]
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_28_info
    Mode: Found
    Sampled Values: ['Found' 'Found' 'Found' 'New' 'Found']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_29_info
    Mode: Found
    Sampled Values: ['Found' 'Found' 'NotFound' 'NotFound' 'Found']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_30_info
    Mode: Windows 10
    Sampled Values: ['Mac OS X 10_10_5' 'Windows 7' nan 'Windows 10' 'Windows 10']
    Number of Total Values: 144233
    Number of Unique Values: 75
  Column: identity_31_info
    Mode: chrome 63.0
    Sampled Values: ['mobile safari 11.0' 'mobile safari 10.0' 'chrome 63.0'
 'ie 11.0 for desktop' 'mobile safari generic']
    Number of Total Values: 144233
    Number of Unique Values: 130
  Column: identity_32_info
    Max: nan
    Min: nan
    Mode: 24.0
    Sampled Values: [24. nan 32. 24. 32.]
    Number of Total Values: 144233
    Number of Unique Values: 4
  Column: identity_33_info
    Mode: 1920x1080
    Sampled Values: ['1680x1050' '1920x1080' '1366x767' '1366x768' nan]
    Number of Total Values: 144233
    Number of Unique Values: 260
  Column: identity_34_info
    Mode: match_status:2
    Sampled Values: ['match_status:2' 'match_status:1' nan nan 'match_status:2']
    Number of Total Values: 144233
    Number of Unique Values: 4
  Column: identity_35_info
    Mode: T
    Sampled Values: ['F' 'F' nan 'F' 'T']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_36_info
    Mode: F
    Sampled Values: ['F' 'F' 'F' 'T' 'F']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_37_info
    Mode: T
    Sampled Values: ['F' 'F' 'T' 'T' 'T']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: identity_38_info
    Mode: F
    Sampled Values: ['T' 'T' 'T' 'F' 'F']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: DeviceType
    Mode: desktop
    Sampled Values: ['mobile' 'desktop' 'desktop' 'desktop' 'desktop']
    Number of Total Values: 144233
    Number of Unique Values: 2
  Column: DeviceInfo
    Mode: Windows
    Sampled Values: ['Windows' nan 'Windows' 'MacOS' 'LG-K410 Build/LRX22G']
    Number of Total Values: 144233
    Number of Unique Values: 1786
  Column: TransactionID
    Max: 3577534
    Min: 2987004
    Mode: 2987004
    Sampled Values: [3023826 3298723 3303458 3096420 3446751]
    Number of Total Values: 144233
    Number of Unique Values: 144233
  Column: id_related_features
Column is multi-dimensional. Probably an embedding type. Usually not of interest


        </dataset_stats>
        <task>
        This task is to predict whether a transaction is fraudulent given the transaction information and user-transaction structural information
        </task>
        <schema>
        {'dataset_name': 'ieeecis', 'tables': [{'name': 'Transaction', 'columns': [{'name': 'ProductCode', 'dtype': 'category', 'description': 'This column likely represents product categories as it has very few unique values.'}, {'name': 'card_meta_info_1', 'dtype': 'float', 'description': 'This column contains numerical values with many unique entries, likely representing some continuous metadata about cards.'}, {'name': 'card_meta_info_2', 'dtype': 'float', 'description': 'This column contains numerical values, likely representing another form of card metadata.'}, {'name': 'card_meta_info_3', 'dtype': 'float', 'description': 'This column contains numerical values with some repetition, likely a type of card classification or limit.'}, {'name': 'card_meta_info_4', 'dtype': 'category', 'description': 'This column represents a small set of unique values, likely indicating the type of card network (e.g., Visa, Mastercard).'}, {'name': 'card_meta_info_5', 'dtype': 'float', 'description': 'This column contains numerical values with moderate unique values, likely related to card properties.'}, {'name': 'card_meta_info_6', 'dtype': 'category', 'description': 'This column likely represents a categorical distinction between credit and debit cards.'}, {'name': 'purchaser billing region', 'dtype': 'float', 'description': 'This column represents numerical values likely associated with geographical regions.'}, {'name': 'purchaser billing country', 'dtype': 'float', 'description': 'This column represents numerical values likely associated with different countries.'}, {'name': 'purchaser email domain', 'dtype': 'category', 'description': 'This column represents email domains, which belong to a small set of unique values.'}, {'name': 'recipient email domain', 'dtype': 'category', 'description': 'Similar to purchaser email domain, this column categorizes recipient email domains.'}, {'name': 'match_1', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_2', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_3', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_4', 'dtype': 'category', 'description': 'Small set of unique values, likely a categorical variable representing a classification.'}, {'name': 'match_5', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_6', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_7', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_8', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'match_9', 'dtype': 'category', 'description': 'Binary categorical column likely representing some matching status.'}, {'name': 'TransactionID', 'dtype': 'primary_key', 'description': 'This column likely represents unique transaction identifiers.'}, {'name': 'isFraud', 'dtype': 'category', 'description': 'Binary column indicating whether a transaction was flagged as fraudulent or not.'}, {'name': 'TransactionAmt', 'dtype': 'float', 'description': 'This column contains numerical values representing transaction amounts.'}, {'name': 'distance', 'dtype': 'float', 'description': 'This column represents multi-dimensional data, likely an embedding related to distances.'}, {'name': 'payment_card_related_counting', 'dtype': 'float', 'description': 'Multi-dimensional embedding likely representing counts related to payment cards.'}, {'name': 'timedelta', 'dtype': 'float', 'description': 'Multi-dimensional embedding likely representing time differences.'}, {'name': 'vesta_features', 'dtype': 'float', 'description': 'Multi-dimensional embedding related to features extracted by Vesta.'}], 'format': 'numpy', 'source': 'data/transaction.npz'}, {'name': 'Identity', 'columns': [{'name': 'identity_12_info', 'dtype': 'category', 'description': 'Binary categorical column indicating whether an identity was found.'}, {'name': 'identity_13_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly indicating a scoring or classification metric.'}, {'name': 'identity_14_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly representing an interval or a score.'}, {'name': 'identity_15_info', 'dtype': 'category', 'description': 'Small set of unique values, likely indicating different identity statuses.'}, {'name': 'identity_16_info', 'dtype': 'category', 'description': 'Binary categorical column indicating identity presence.'}, {'name': 'identity_17_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly representing a classification.'}, {'name': 'identity_18_info', 'dtype': 'float', 'description': 'This column contains numerical values with some missing data, likely another classification score.'}, {'name': 'identity_19_info', 'dtype': 'float', 'description': 'This column contains numerical values with a large set of unique values, possibly a geographic or behavioral score.'}, {'name': 'identity_20_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly a score or classification metric.'}, {'name': 'identity_21_info', 'dtype': 'float', 'description': 'This column contains numerical values, likely representing a classification metric.'}, {'name': 'identity_22_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly another classification metric.'}, {'name': 'identity_23_info', 'dtype': 'category', 'description': 'This column represents categorical values, likely indicating IP proxy statuses.'}, {'name': 'identity_24_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly another classification metric.'}, {'name': 'identity_25_info', 'dtype': 'float', 'description': 'This column contains numerical values with a large set of unique values, possibly an identifier or classification score.'}, {'name': 'identity_26_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly a score or classification metric.'}, {'name': 'identity_27_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some identity presence.'}, {'name': 'identity_28_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some identity presence.'}, {'name': 'identity_29_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some identity presence.'}, {'name': 'identity_30_info', 'dtype': 'category', 'description': 'Categorical column representing operating system versions.'}, {'name': 'identity_31_info', 'dtype': 'category', 'description': 'Categorical column representing browser versions.'}, {'name': 'identity_32_info', 'dtype': 'float', 'description': 'This column contains numerical values, possibly related to a classification metric.'}, {'name': 'identity_33_info', 'dtype': 'category', 'description': 'Categorical column representing screen resolutions.'}, {'name': 'identity_34_info', 'dtype': 'category', 'description': 'Categorical column indicating a match status.'}, {'name': 'identity_35_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some matching status.'}, {'name': 'identity_36_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some matching status.'}, {'name': 'identity_37_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some matching status.'}, {'name': 'identity_38_info', 'dtype': 'category', 'description': 'Binary categorical column indicating some matching status.'}, {'name': 'DeviceType', 'dtype': 'category', 'description': 'Binary categorical column indicating whether the device is mobile or desktop.'}, {'name': 'DeviceInfo', 'dtype': 'category', 'description': 'Categorical column representing different device information.'}, {'name': 'TransactionID', 'dtype': 'primary_key', 'description': 'This column likely represents unique transaction identifiers.'}, {'name': 'id_related_features', 'dtype': 'float', 'description': 'This column represents multi-dimensional data, likely an embedding related to identity features.'}], 'format': 'numpy', 'source': 'data/identity.npz'}], 'tasks': [{'name': 'fraud', 'task_type': 'classification', 'target_column': 'isFraud', 'target_table': 'Transaction', 'evaluation_metric': 'auroc', 'format': 'numpy', 'source': 'fraud/{split}.npz', 'columns': [{'name': 'ProductCode', 'dtype': 'category'}, {'name': 'card_meta_info_1', 'dtype': 'float'}, {'name': 'card_meta_info_2', 'dtype': 'float'}, {'name': 'card_meta_info_3', 'dtype': 'float'}, {'name': 'card_meta_info_4', 'dtype': 'category'}, {'name': 'card_meta_info_5', 'dtype': 'float'}, {'name': 'card_meta_info_6', 'dtype': 'category'}, {'name': 'purchaser billing region', 'dtype': 'float'}, {'name': 'purchaser billing country', 'dtype': 'float'}, {'name': 'purchaser email domain', 'dtype': 'category'}, {'name': 'recipient email domain', 'dtype': 'category'}, {'name': 'match_1', 'dtype': 'category'}, {'name': 'match_2', 'dtype': 'category'}, {'name': 'match_3', 'dtype': 'category'}, {'name': 'match_4', 'dtype': 'category'}, {'name': 'match_5', 'dtype': 'category'}, {'name': 'match_6', 'dtype': 'category'}, {'name': 'match_7', 'dtype': 'category'}, {'name': 'match_8', 'dtype': 'category'}, {'name': 'match_9', 'dtype': 'category'}, {'name': 'TransactionID', 'dtype': 'category'}, {'name': 'isFraud', 'dtype': 'category'}, {'name': 'TransactionAmt', 'dtype': 'float'}, {'name': 'distance', 'dtype': 'float'}, {'name': 'payment_card_related_counting', 'dtype': 'float'}, {'name': 'timedelta', 'dtype': 'float'}, {'name': 'vesta_features', 'dtype': 'float'}]}]}
        </schema>
        Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
        <similarity>
        The pair with the 1st highest similarity is column "card_meta_info_3" from Table "Transaction" and column "card_meta_info_5" from Table "Transaction" with similarity 0.985
The pair with the 2nd highest similarity is column "identity_19_info" from Table "Identity" and column "identity_20_info" from Table "Identity" with similarity 0.978
The pair with the 3rd highest similarity is column "identity_17_info" from Table "Identity" and column "identity_26_info" from Table "Identity" with similarity 0.976
The pair with the 4th highest similarity is column "identity_19_info" from Table "Identity" and column "identity_25_info" from Table "Identity" with similarity 0.958
The pair with the 5th highest similarity is column "identity_20_info" from Table "Identity" and column "identity_25_info" from Table "Identity" with similarity 0.958
The pair with the 6th highest similarity is column "card_meta_info_3" from Table "Transaction" and column "identity_17_info" from Table "Identity" with similarity 0.937
The pair with the 7th highest similarity is column "card_meta_info_5" from Table "Transaction" and column "identity_17_info" from Table "Identity" with similarity 0.931
The pair with the 8th highest similarity is column "identity_19_info" from Table "Identity" and column "identity_21_info" from Table "Identity" with similarity 0.923
The pair with the 9th highest similarity is column "identity_20_info" from Table "Identity" and column "identity_21_info" from Table "Identity" with similarity 0.920
The pair with the 10th highest similarity is column "card_meta_info_3" from Table "Transaction" and column "identity_26_info" from Table "Identity" with similarity 0.918

        </similarity>
        </input>
        Return your output in the json format inside <selection></selection>.
    