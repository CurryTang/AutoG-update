
        Imagine you are an expert graph data scientist, and now you are expected to construct graph schema based on the original
        inputs. You will be given an original schema represented in the dictionary format:
        <data>
            1. dataset_name: name of the dataset 
            2. tables: meta data for list of tables, each one will present following attributes
                1. name: table name
                2. source: source of the data, can either be a numpy .npz file or a parquet file
                3. columns: list of columns, each column will have following attributes
                    1. name: column name
                    2. dtype: column type, can be either text, categorical, float, primary_key, foreign_key, or multi_category.
                    primary_key and foreign_key are two special types of categorical columns, which presents a structural
                    relationship with other tables. Multi_category means this column is of list type, and each cell main contains
                    a list of categorical values. After a column is set as primary_key or foreign_key, it should not be changed to other types.
                    3. link_to (optional): if this column is a foreign key, point to which primary key from which table
            3. statistics of the table: statistics of the column value of tables. These statistics can be used to help you
            determine the characteristics of the columns. For example, if one categorical column only contains one unique value,
            then creating a node type based on this column can result in a super node, which is not ideal for graph construction.
            You should also determine whether two columns represent the same thing based on these statistics. 
            4. Dummy table is a special type of table. It's not explicitly defined with a table slot. It's defined in other tables, such as
            {"name": "nation", "dtype": "foreign_key", "link_to": "Country.CountryID"}. In this case, "Country" is a dummy table, which is not 
            explicitly defined in the tables slot.
        </data>                
        Here are the documents of the actions:
        
        Here is the introduction of the function generate_or_connect_dummy_table:
Description:
This function can be used in two ways:
1. Generate a dummy table with only one primary key
2. Turn an existing column with categorical type to an existing dummy table
"orig_col_name" must be a column with category type
Parameters:
dbb: the database object
base_table_name: the name of the original table
orig_col_name: the name of the original column in the original table, this should be a column with category type
new_table_name: the name of the new table to be created/connected
new_col_name: the name of the new column to be created/connected

Here is the introduction of the function connect_two_columns:
Description:
Connect two columns, this function can be used for the following case. Always put the column with category type in table 1.
1. A category column in table 1 is connected to a category column in table 2, in this case, a new dummy table will be created
2. A category column in table 1 is connected to a primary key column in table 2, in this case, the column in table 1 will be turned into a foreign key column. In case 2, table_2_col_name must be a primary key column
3. A category column in table 1 is connected to a non-category and non-primary key column in table 2, in this case, we will use a trick called Surrogate Key. 
4. If the column in table 1 is already a foreign key, then in this case it's probably a multi-column-point-to-one case, we need to update other fk columns too.
Parameters:
dbb: the database object
table_1_name: the name of the first table, 
table_1_col_name: the name of the column in the first table, this should be a column with category type
table_2_name: the name of the second table
table_2_col_name: the name of the column in the second table, this should be a column with category type

Here is the introduction of the function explode_multi_category_column:
Description:
Explode a multi-category column into multiple columns. You should determine whether to use this function. If you don't explode a multi-category column, it will be treated as a single category column automatically.
Parameters:
dbb: the database object
original_table: name of the original table where the multi-category column is located
multi_cat_col: the name of the multi-category column
primary_key_column: the name of the primary key column in the original table
new_table_name: the name of the new table to be created
new_col_name: the name of the new column to be created
dtype: the data type of the new column, if set to "foreign_key", this table will contain only "foreign_keys". In this case, it means you only want to use this column's relaion. If set to other types, this table will contain the original column's values, and a primary key will be added, this means you want to use this column's values.

Here is the introduction of the function generate_non_dummy_table:
Description:
Generate a non-dummy table with columns in the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
cols: the list of columns to be included in the new table and removed from the original table
new_table_name: the name of the new table to be created

Here is the introduction of the function remove_primary_key:
Description:
Remove a primary key constraint from a column in the original table
If the column is just an index, then the column will be removed from the table.
For example, if the schema is like {
    {"name": "id", "dtype": "primary_key"},
    {"name": "user", "dtype": "foreign_key", "link_to": "user.userID"},
    {"name": "book", "dtype": "foreign_key", "link_to": "book.bookID"},
}
In such case, it's clear that this table represents the role of an edge, while the presence of primary key prevents heuristic to turn this table into an edge. Primary key is not needed in this case.
In such case, we will remove the primary key constraint from the column.
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the column in the original table

Here is the introduction of the function add_primary_key:
Description:
Add a primary key column to the original table
Parameters:
dbb: the database object
base_table_name: the name of the original table
col_name: the name of the newly added primary key column

        
        Now, you need to 
        1. Actively think about whether any one of the four actions should be conducted; If not, you can select "None" and then halt the program.
        2. output all actions you can think of from the above list to perform, and output your selection in the following format. It should be noted that for those actions with sequential relation like one new categorical column generated after expanding a multi-category column, you don't need to generate in one round.
        
        <selection>
        [{'explanation': <explanation for the selection>, 'action': <first action>, 'parameters': <parameters for the first action> },
        {'explanation': <explanation for the selection>, 'action': <second action>, 'parameters': <parameters for the second action> }, ...
        ]
        </selection>

        
        3. If not more action, output <selection>None</selection>
        
        Example:
        
Table: Paper
{
  "Column": "PaperID",
  "data type": "primary_key"
}
{
    "Column": "Title",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Transformers",
    "5 sampled values": [
        "Transformers",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning",
        "Computer Vision"
    ]
}
{
    "Column": "Authors",
    "data type": "multi_category",
    "Number of unique values": 987,
    "Number of nan values": 0,
    "Number of total values": 74320,
    "Mode values": "Yann LeCun",
    "5 sampled values": [
        "Yann LeCun",
        "Geoffrey Hinton",
        "Yoshua Bengio",
        "Fei-Fei Li",
        "Jitendra Malik"
    ]
}
{
    "Column": "Journal",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "Year",
    "data type": "float",
}
{
    "Column": "Keywords",
    "data type": "category",
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "Machine Learning",
    "5 sampled values": [
        "Machine Learning",
        "Deep Learning",
        "Graph Neural Networks",
        "Reinforcement Learning",
        "Meta Learning"
    ]
}
{
    "Column": "Abstract",
    "data type": "text",
    "Number of unique values": 10000,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": "This paper presents a new model for graph neural networks.",
    "5 sampled values": [
        "This paper presents a new model for graph neural networks.",
        "This paper introduces a new reinforcement learning algorithm.",
        "This paper presents a new model for transformers.",
        "This paper presents a new model for meta learning.",
        "This paper presents a new model for computer vision."
    ]
}
{
    "Column": "Category",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 10000,
    "Mode values": 3,
    "5 sampled values": [
        3,
        4,
        1,
        6,
        9
    ]
}
{
  "Column": "ItemID",
  "data type": "foreign_key"
}
Table: Journal
{
  "Column": "JournalID",
  "data type": "primary_key"
}
{
  "Column": "Name",
  "data type": "text", 
    "Number of unique values": 100,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Nature",
    "5 sampled values": [
        "Nature",
        "Science",
        "NeurIPS",
        "ICML",
        "CVPR"
    ]
}
{
    "Column": "ImpactFactor",
    "data type": "float"
}
{
    "Column": "Country",
    "data type": "category",
    "Number of unique values": 10,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}
{
    "Column": "Publisher",
    "data type": "text",
    "Number of unique values": 9,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "Springer",
    "5 sampled values": [
        "Springer",
        "Elsevier",
        "ACM",
        "IEEE",
        "Nature"
    ]
}
{
    "Column": "PublisherLocation",
    "data type": "category",
    "Number of unique values": 5,
    "Number of nan values": 0,
    "Number of total values": 100,
    "Mode values": "USA",
    "5 sampled values": [
        "USA",
        "USA",
        "Canada",
        "UK",
        "USA"
    ]
}

</dataset_stats>
<tasks>
Now I want to train a model which can predict the category of a paper based on the information in the paper.
</tasks>
<schema>
{
        "dataset_name": "Papers",
        "tables": [
            {
                "name": "Paper",
                "source": "data/paper.npz",
                "columns": [
                    {"name": "PaperID", "dtype": "primary_key"},
                    {"name": "Title", "dtype": "text"},
                    {"name": "Authors", "dtype": "multi_category"},
                    {"name": "Journal", "dtype": "category"},
                    {"name": "Year", "dtype": "float"},
                    {"name": "Keywords", "dtype": "category"},
                    {"name": "Abstract", "dtype": "text"},
                    {"name": "Category", "dtype": "category"}
                ]
            }, 
            {
                "name": "Journal",
                "source": "data/journal.npz",
                "columns": [
                    {"name": "JournalID", "dtype": "primary_key"},
                    {"name": "Name", "dtype": "text"},
                    {"name": "ImpactFactor", "dtype": "float"},
                    {"name": "Country", "dtype": "category"},
                    {"name": "Publisher", "dtype": "text"},
                    {"name": "PublisherLocation", "dtype": "category"}
                ]
            }
        ]
    }
</schema>
Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
<similarity>
The pair with the 1st highest similarity is column "Journal" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.885
The pair with the 2nd highest similarity is column "Authors" from Table "Paper" and column "Name" from Table "Journal" with similarity 0.743
The pair with the 3rd highest similarity is column "Authors" from Table "Paper" and column "Country" from Table "Journal" with similarity 0.723
</similarity>
</input>



We need to think about whether we need to do one of the six actions:
1. First, for explode_multi_category_column, the Authors of the paper are in a multi-category column. Moreover, author is closely related to the category of the paper, so the relationship Paper-Author-Paper can be very useful. So, we need to explode this multi category column.
2. For connect_two_columns, the Journal column in the Paper table and the  column Name in the Journal table are highly similar, so we can connect these two columns with a foreign key constraint. Other pairs like Authors and Name, Authors and Country are not similar enough to be connected.
3. For generate_non_dummy_table, the Publisher and PublisherLocation columns are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns.
4. For generate_or_connect_dummy_table, we need to find those categorical columns beneficial for downstream task. We have categorical columns (Journal has been deleted in step 2, Category is the final objective) Keyword, Country, this will result in relationship Paper-Keyword-Paper and Paper-Journal-Country-Journal-Paper respectively. Since the target is to predict the category of a paper, we can generate a dummy table for the column Keyword since paper sharing the same keyword are highly likely to share the same category. Country may be not beneficial since it doesn't present a strong semantic relationship with the category. 
5. For remove_primary_key and add_primary_key, there's no unreasonable primary key or missing primary key in the table, so we don't need to do this action. as a result, we have the following actions
<selection>
        [{{'explanation': "Author is multi-category and Paper-Author-Paper is probably useful. We set the dtype to foreign_key because we want to use the relation", 'action': 'explode_multi_category_column', 'parameters': {'original_table': 'Paper', 'multi_cat_col': 'Author', primary_key_column: 'PaperID', 'new_table_name': 'Author', 'new_col_name': 'AuthorName', 'dtype': 'foreign_key'}},
        {{'explanation': 'the Journal column in the Paper table and the  column Name in the Journal table are highly similar, both of them should refer to the name of the journal', 'action': 'connect_two_columns', 'parameters': {'table_1_name': 'Paper', 'table_1_col_name': 'Journal', 'table_2_name': 'Journal', 'table_2_col_name': 'Name', 'new_table_name': "", 'new_table_col_name': "" }}, 
        {{'explanation': 'Publisher and PublisherLocation are independent columns for the entity Publisher. We can generate a new table Publisher with these two columns', 'action': 'generate_non_dummy_table', 'parameters': {'base_table_name': 'Paper', 'cols': ['Publisher', 'PublisherLocation'],  'new_table_name': 'Publisher'}},
        {{'explanation': 'Keyword is a categorical column which can be used to generate a dummy table. Country is not beneficial for the downstream task', 'action': 'generate_or_connect_dummy_table', 'parameters': {'base_table_name': 'Paper', 'orig_col_name': 'Keyword', 'new_table_name': 'Keyword', 'new_col_name': 'Keyword'}},
        ]
        </selection>

    

        
        History Actions:
        First iteration, no history yet


        
        <input>
        <dataset_stats>
        Analysis for Table Movies:
  Column: movieID
    Max: 193609
    Min: 1
    Mode: 1
    Sampled Values: [   313  27618   4054   5673 116138]
    Number of Total Values: 9742
    Number of Unique Values: 9742
  Column: title
    Mode: Confessions of a Dangerous Mind (2002)
    Sampled Values: ['Dead Zone, The (1983)...', 'Signal, The (2014)...', 'Wedding Banquet, The (Xi yan) (1993)...', 'Anniversary Party, The (2001)...', "William Shakespeare's Romeo + Juliet (1996)..."]
    Number of Total Values: 9742
    Number of Unique Values: 9737
  Column: genres
Column is a list. Probably a multi-category column. If you explode it, it will have 20 unique elements from total 22084, and mode Drama. Before exploding, there are 9742, out of 951 is unique. Please consider whether you should explode it, you should explode it if it can bring strong network effect.

Analysis for Table Ratings:
  Column: ratingID
    Max: 100835
    Min: 0
    Mode: 0
    Sampled Values: [86873 75139 89125 90378  5403]
    Number of Total Values: 100836
    Number of Unique Values: 100836
  Column: rate_user
    Max: 610
    Min: 1
    Mode: 414
    Sampled Values: [331 567 125 295 156]
    Number of Total Values: 100836
    Number of Unique Values: 610
  Column: rate_movie
    Max: 193609
    Min: 1
    Mode: 356
    Sampled Values: [107013  38038    344   5682   1475]
    Number of Total Values: 100836
    Number of Unique Values: 9724
  Column: rating
    Max: 5.0
    Min: 0.5
    Mode: 4.0
    Sampled Values: [3.  0.5 3.5 4.5 4.5]
    Number of Total Values: 100836
    Number of Unique Values: 10
  Column: timestamp
    Max: 2018-09-24T10:27:30.000000000
    Min: 1996-03-29T13:36:55.000000000
    Mode: 2016-04-04 12:39:58
    Sampled Values: ['2007-04-03T18:00:06.000000000' '2018-02-06T17:09:45.000000000'
 '2009-06-15T04:57:31.000000000' '2006-03-07T19:10:50.000000000'
 '1996-08-29T13:55:41.000000000']
    Number of Total Values: 100836
    Number of Unique Values: 85043

Analysis for Table Tags:
  Column: tag_user
    Max: 610
    Min: 2
    Mode: 474
    Sampled Values: [599  62 474 474 567]
    Number of Total Values: 3683
    Number of Unique Values: 58
  Column: tag_movie
    Max: 193565
    Min: 1
    Mode: 296
    Sampled Values: [3260 4144  296 7451  296]
    Number of Total Values: 3683
    Number of Unique Values: 1572
  Column: tag
    Mode: In Netflix queue
    Sampled Values: ['organized crime...', 'Girl Power...', 'feel-good...', 'Bugs Bunny...', 'psychology...']
    Number of Total Values: 3683
    Number of Unique Values: 1589
  Column: timestamp
    Max: 2018-09-16T07:50:03.000000000
    Min: 2006-01-13T14:09:12.000000000
    Mode: 2006-01-14 15:39:52
    Sampled Values: ['2018-05-02T14:31:53.000000000' '2018-05-02T15:01:48.000000000'
 '2007-08-08T12:01:57.000000000' '2017-06-26T01:55:22.000000000'
 '2006-01-15T20:20:06.000000000']
    Number of Total Values: 3683
    Number of Unique Values: 3411


        </dataset_stats>
        <task>
        This task is to predict user's ratings on movies given movie information and movie-user structural information
        </task>
        <schema>
        {"dataset_name":"movielens","tables":[{"name":"Movies","source":"data/movies.pqt","format":"parquet","columns":[{"name":"movieID","dtype":"primary_key","description":"This column is probably representing the unique identifier for each movie, as it has a lot of unique values and ranges from 1 to 193609."},{"name":"title","dtype":"text","description":"This column contains the titles of the movies, which are unique text identifiers for each film."},{"name":"genres","dtype":"multi_category","description":"This column represents the genres associated with each movie, often containing multiple categories per movie."}],"time_column":null},{"name":"Ratings","source":"data/ratings.pqt","format":"parquet","columns":[{"name":"ratingID","dtype":"primary_key","description":"This column is likely a unique identifier for each rating entry, as it ranges from 0 to 100835."},{"name":"rate_user","dtype":"category","description":"This column probably represents the user ID who gave the rating, as it ranges from 1 to 610, indicating a limited set of users."},{"name":"rate_movie","dtype":"category","description":"This column likely represents the movie ID that was rated, as it ranges from 1 to 193609, matching the movieID range in the Movie table."},{"name":"rating","dtype":"category","description":"This column contains the rating values given by users, ranging from 0.5 to 5.0, which are typical for rating systems."},{"name":"timestamp","dtype":"datetime","description":"This column records the exact date and time when the rating was given, as indicated by the datetime format."}],"time_column":null},{"name":"Tags","source":"data/tags.pqt","format":"parquet","columns":[{"name":"tag_user","dtype":"category","description":"This column likely represents the user ID who assigned the tag, as it ranges from 2 to 610, similar to the rate_user column in the Ratings table."},{"name":"tag_movie","dtype":"category","description":"This column probably represents the movie ID that was tagged, as it ranges from 1 to 193565, closely matching the movieID range in the Movie table."},{"name":"tag","dtype":"text","description":"This column contains the text of the tags assigned by users, which are descriptive labels."},{"name":"timestamp","dtype":"datetime","description":"This column records the exact date and time when the tag was assigned, as indicated by the datetime format."}],"time_column":null}],"tasks":[{"name":"ratings","source":"ratings/{split}.pqt","format":"parquet","columns":[{"name":"rate_user","dtype":"category"},{"name":"rate_movie","dtype":"category"},{"name":"rating","dtype":"category"},{"name":"timestamp","dtype":"datetime"},{"name":"ratingID","dtype":"category"}],"time_column":null,"evaluation_metric":"auroc","target_column":"rating","target_table":"Ratings","task_type":"classification","key_prediction_label_column":"label","key_prediction_query_idx_column":"query_idx"}],"method":"r2n","column_groups":null}
        </schema>
        Here we gives the similarity score of each column pair, you can use this information to determine whether two columns may be joinable. The similarity score is scaled to [0, 1], the larger means the more similar.
        <similarity>
        The pair with the 1st highest similarity is column "rate_movie" from Table "Ratings" and column "tag_movie" from Table "Tags" with similarity 0.825
The pair with the 2nd highest similarity is column "rate_user" from Table "Ratings" and column "tag_user" from Table "Tags" with similarity 0.733
The pair with the 3rd highest similarity is column "movieID" from Table "Movies" and column "rate_movie" from Table "Ratings" with similarity 0.680
The pair with the 4th highest similarity is column "movieID" from Table "Movies" and column "tag_movie" from Table "Tags" with similarity 0.678
The pair with the 5th highest similarity is column "rate_user" from Table "Ratings" and column "rate_movie" from Table "Ratings" with similarity 0.669
The pair with the 6th highest similarity is column "tag_user" from Table "Tags" and column "tag_movie" from Table "Tags" with similarity 0.585
The pair with the 7th highest similarity is column "rate_user" from Table "Ratings" and column "tag_movie" from Table "Tags" with similarity 0.518
The pair with the 8th highest similarity is column "rate_movie" from Table "Ratings" and column "tag_user" from Table "Tags" with similarity 0.508
The pair with the 9th highest similarity is column "movieID" from Table "Movies" and column "rate_user" from Table "Ratings" with similarity 0.339
The pair with the 10th highest similarity is column "movieID" from Table "Movies" and column "tag_user" from Table "Tags" with similarity 0.338
The pair with the 11st highest similarity is column "ratingID" from Table "Ratings" and column "rating" from Table "Ratings" with similarity 0.322
The pair with the 12nd highest similarity is column "movieID" from Table "Movies" and column "ratingID" from Table "Ratings" with similarity 0.312
The pair with the 13rd highest similarity is column "ratingID" from Table "Ratings" and column "tag_movie" from Table "Tags" with similarity 0.291
The pair with the 14th highest similarity is column "ratingID" from Table "Ratings" and column "rate_movie" from Table "Ratings" with similarity 0.252
The pair with the 15th highest similarity is column "ratingID" from Table "Ratings" and column "tag_user" from Table "Tags" with similarity 0.187
The pair with the 16th highest similarity is column "ratingID" from Table "Ratings" and column "rate_user" from Table "Ratings" with similarity 0.160
The pair with the 17th highest similarity is column "rate_movie" from Table "Ratings" and column "rating" from Table "Ratings" with similarity 0.070
The pair with the 18th highest similarity is column "rate_user" from Table "Ratings" and column "rating" from Table "Ratings" with similarity 0.056
The pair with the 19th highest similarity is column "rating" from Table "Ratings" and column "tag_movie" from Table "Tags" with similarity 0.037
The pair with the 20th highest similarity is column "movieID" from Table "Movies" and column "rating" from Table "Ratings" with similarity -0.028

        </similarity>
        </input>
        Return your output in the json format inside <selection></selection>.
    